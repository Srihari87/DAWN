{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains experiment with the mapping function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:42.891732Z",
     "start_time": "2020-08-26T08:48:42.863492Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:44.300563Z",
     "start_time": "2020-08-26T08:48:43.075549Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import configparser\n",
    "import copy\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.utils.data as data\n",
    "import torchvision as tv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import config_helper\n",
    "import filter as watermark_filter\n",
    "import logger\n",
    "import models\n",
    "import score\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "log = logger.Logger(prefix=\">>>\")\n",
    "\n",
    "class SimpleDataset(data.Dataset):\n",
    "    def __init__(self, dataset: List[Tuple[Any, int]]) -> None:\n",
    "        self.data, self.labels = zip(*dataset)\n",
    "        self.count = len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index: int) -> (Any, int):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:44.339706Z",
     "start_time": "2020-08-26T08:48:44.303206Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_data(dataset_name: str, victim_data_path: str, input_size: int) -> (data.Dataset, data.Dataset):\n",
    "    mean = [0.5, 0.5, 0.5]\n",
    "    std = [0.5, 0.5, 0.5]\n",
    "\n",
    "    if dataset_name == \"MNIST\":\n",
    "        dataset = tv.datasets.MNIST\n",
    "        transformations = tv.transforms.Compose([\n",
    "            tv.transforms.ToTensor(),\n",
    "            tv.transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    else:\n",
    "        log.error(\"MNIST is the only supported datasets at the moment. Throwing...\")\n",
    "        raise ValueError(dataset_name)\n",
    "\n",
    "    train_set = dataset(victim_data_path, train=True, transform=transformations, download=True)\n",
    "    test_set = dataset(victim_data_path, train=False, transform=transformations, download=True)\n",
    "    \n",
    "    log.info(\"Training ({}) samples: {}\\nTest samples: {}\\nSaved in: {}\".format(dataset_name, len(train_set), len(test_set), victim_data_path))\n",
    "    return train_set, test_set\n",
    "\n",
    "\n",
    "def setup_victim_model(model_architecture: str, model_path: str, number_of_classes: int) -> nn.Module:\n",
    "    available_models = {\n",
    "        \"MNIST_L5\": models.MNIST_L5_with_latent,\n",
    "    }\n",
    "\n",
    "    model = available_models[model_architecture]()\n",
    "\n",
    "    if model is None:\n",
    "        log.error(\"Incorrect model architecture specified or architecture not available.\")\n",
    "        raise ValueError(model_architecture)\n",
    "\n",
    "    models.load_state(model, model_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_file(file_path: str) -> List[Tuple]:\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def test_model(model: nn.Module, test_set: data.DataLoader, number_of_classes: int) -> (score.FloatScore, score.DictScore):\n",
    "    \"\"\"Test the model on the test dataset.\"\"\"\n",
    "    # model.eval is used for ImageNet models, batchnorm or dropout layers will work in eval mode.\n",
    "    model.eval()\n",
    "\n",
    "    def test_average() -> score.FloatScore:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for (inputs, yreal) in tqdm(test_set, unit=\"images\", desc=\"Testing model (average)\", leave=True, ascii=True):\n",
    "                inputs, yreal = inputs.cuda(), yreal.cuda()\n",
    "\n",
    "                ypred, _ = model(inputs)\n",
    "                _, predicted = torch.max(ypred.data, 1)\n",
    "\n",
    "                total += yreal.size(0)\n",
    "                correct += (predicted == yreal).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        log.info(\"Accuracy of the network on the {} test images (average): {}\".format(total, accuracy))\n",
    "        with open('epoch_logs.txt', 'a+') as file:\n",
    "            file.write('Test Acc: {}\\n'.format(accuracy))\n",
    "        return score.FloatScore(accuracy)\n",
    "\n",
    "    def test_per_class() -> score.DictScore:\n",
    "        class_correct = list(0. for _ in range(number_of_classes))\n",
    "        class_total = list(0. for _ in range(number_of_classes))\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (inputs, yreal) in tqdm(test_set, unit=\"images\", desc=\"Testing model (per class)\", leave=True, ascii=True):\n",
    "                inputs, yreal = inputs.cuda(), yreal.cuda()\n",
    "\n",
    "                total += yreal.size(0)\n",
    "\n",
    "                ypred, _ = model(inputs)\n",
    "                _, predicted = torch.max(ypred, 1)\n",
    "                c = (predicted == yreal).squeeze()\n",
    "                for i in range(yreal.shape[0]):\n",
    "                    label = yreal[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "\n",
    "        log.info(\"Accuracy of the network on the {} test images (per-class):\".format(total))\n",
    "\n",
    "        per_class_accuracy = {}\n",
    "        for i in range(number_of_classes):\n",
    "            accuracy = 100 * class_correct[i] / (class_total[i] + 0.0001)\n",
    "            per_class_accuracy[i] = accuracy\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                i, accuracy))\n",
    "\n",
    "        return score.DictScore(per_class_accuracy)\n",
    "\n",
    "    return test_average(), test_per_class()\n",
    "\n",
    "\n",
    "def get_shapes(model: nn.Module, test_set: data.DataLoader) -> (torch.Size, List[torch.Size]):\n",
    "    \"\"\"Returns input and latent sizes.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for (inputs, yreal) in test_set:\n",
    "            inputs, yreal = inputs.cuda(), yreal.cuda()\n",
    "\n",
    "            ypred, latents = model(inputs)\n",
    "            watermark_shape = inputs[0].cpu().shape\n",
    "            latents_shapes = [torch.Size([l.cpu().shape[1]]) for l in latents]\n",
    "            break\n",
    "\n",
    "    return watermark_shape, latents_shapes\n",
    "\n",
    "\n",
    "def compare_distributions(\n",
    "    model: nn.Module, test_set: data.DataLoader,\n",
    "    wf: watermark_filter.WatermarkFilter,\n",
    "    wf_latents: List[watermark_filter.WatermarkFilter]) -> List[List]:\n",
    "    \n",
    "    with_wm_orig = 0\n",
    "    without_wm_orig = 0\n",
    "\n",
    "    latent_n = len(wf_latents)\n",
    "    latent_batches = [[] for _ in range(latent_n)]\n",
    "    with_without = [\n",
    "    {\n",
    "        \"with_wm_latent\": 0,\n",
    "        \"without_wm_latent\": 0\n",
    "    } \n",
    "    for _ in range(latent_n)]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, _) in tqdm(test_set, unit=\"images\", desc=\"Watermark Filter\", leave=True, ascii=True):\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "            model.eval()\n",
    "            _, latents = model(inputs)\n",
    "            inputs = inputs.cpu()\n",
    "\n",
    "\n",
    "            for x in inputs:\n",
    "                if wf.is_watermark(x):\n",
    "                    with_wm_orig += 1\n",
    "                else:\n",
    "                    without_wm_orig += 1\n",
    "\n",
    "            for i in range(latent_n):\n",
    "                lat_repr = latents[i].cpu()\n",
    "                latent_batches[i].append(lat_repr)\n",
    "                \n",
    "                for x in lat_repr:\n",
    "                    if wf_latents[i].is_watermark(x):\n",
    "                        with_without[i][\"with_wm_latent\"] += 1\n",
    "                    else:\n",
    "                        with_without[i][\"without_wm_latent\"] += 1\n",
    "\n",
    "    log.info(\"Watermarked: {}\".format(with_wm_orig))\n",
    "    log.info(\"Not watermarked: {}\".format(without_wm_orig))\n",
    "    log.info(\"Ratio: {}\".format(with_wm_orig * 100 / without_wm_orig))\n",
    "\n",
    "    for i in range(latent_n):\n",
    "        log.info(\"Watermarked latent: {}\".format(with_without[i][\"with_wm_latent\"]))\n",
    "        log.info(\"Not watermarked latent: {}\".format(with_without[i][\"without_wm_latent\"]))\n",
    "        log.info(\"Ratio latent: {}\".format(with_without[i][\"with_wm_latent\"] * 100 / with_without[i][\"without_wm_latent\"]))\n",
    "\n",
    "    \n",
    "    return latent_batches\n",
    "\n",
    "\n",
    "def perturb(img, e, min_pixel=-1., max_pixel=1.):\n",
    "    r = max_pixel - min_pixel\n",
    "    b = r * torch.rand(img.shape)\n",
    "    b += min_pixel\n",
    "    noise = e * b\n",
    "    noise = noise.cuda()\n",
    "\n",
    "    return torch.clamp(img + noise, min_pixel, max_pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:44.356422Z",
     "start_time": "2020-08-26T08:48:44.341365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEFAULT]\n",
      "batch_size: 1024\n",
      "dataset_name: MNIST\n",
      "input_size: 28\n",
      "number_of_classes: 10\n",
      "model_architecture: MNIST_L5\n",
      "test_save_path: data/datasets/MNIST\n",
      ">>> INFO: Victim model path: data/models/victim_mnist_l5.pt.\n"
     ]
    }
   ],
   "source": [
    "config = config_helper.load_config(\"configurations/mapping/mapping-mnist-l5.ini\")\n",
    "\n",
    "victim_path = \"data/models/victim_mnist_l5.pt\"\n",
    "\n",
    "config_helper.print_config(config)\n",
    "log.info(\"Victim model path: {}.\".format(victim_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:47.330937Z",
     "start_time": "2020-08-26T08:48:44.357595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading state from: data/models/victim_mnist_l5.pt\n",
      ">>> INFO: Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "#  Setup model architecture and load models from file.\n",
    "model_victim = setup_victim_model(\n",
    "    config[\"DEFAULT\"][\"model_architecture\"],\n",
    "    victim_path,\n",
    "    int(config[\"DEFAULT\"][\"number_of_classes\"]))\n",
    "\n",
    "device_string = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device_string)\n",
    "log.info(\"Using device: {}\".format(device_string))\n",
    "\n",
    "model_victim = model_victim.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:49.109425Z",
     "start_time": "2020-08-26T08:48:47.332014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> INFO: Training (MNIST) samples: 60000\n",
      "Test samples: 10000\n",
      "Saved in: data/datasets/MNIST\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e4da837ab143a1892610a392b16120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Testing model (average)', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: Accuracy of the network on the 10000 test images (average): 99.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fee84865684ea0827d9254b720f2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Testing model (per class)', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: Accuracy of the network on the 10000 test images (per-class):\n",
      "Accuracy of     0 : 99 %\n",
      "Accuracy of     1 : 99 %\n",
      "Accuracy of     2 : 99 %\n",
      "Accuracy of     3 : 99 %\n",
      "Accuracy of     4 : 99 %\n",
      "Accuracy of     5 : 99 %\n",
      "Accuracy of     6 : 98 %\n",
      "Accuracy of     7 : 99 %\n",
      "Accuracy of     8 : 98 %\n",
      "Accuracy of     9 : 98 %\n",
      ">>> INFO: Input shape: torch.Size([1, 28, 28])\n",
      ">>> INFO: Latent shape: torch.Size([200])\n",
      ">>> INFO: Latent shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "#  Load test set and transform it.\n",
    "train_set, test_set = download_data(\n",
    "    config[\"DEFAULT\"][\"dataset_name\"],\n",
    "    config[\"DEFAULT\"][\"test_save_path\"],\n",
    "    int(config[\"DEFAULT\"][\"input_size\"])\n",
    ")\n",
    "\n",
    "batch_size = config[\"DEFAULT\"][\"batch_size\"]\n",
    "train_set = data.DataLoader(train_set, batch_size=int(batch_size), shuffle=True, num_workers=4)\n",
    "test_set = data.DataLoader(test_set, batch_size=int(batch_size), shuffle=False, num_workers=4)\n",
    "_, _ = test_model(model_victim, test_set, int(config[\"DEFAULT\"][\"number_of_classes\"]))\n",
    "\n",
    "#  Determine size of the watermark filter\n",
    "watermark_shape, watermark_latent_shapes = get_shapes(model_victim, test_set)\n",
    "log.info(\"Input shape: {}\".format(watermark_shape))\n",
    "for latent_shape in watermark_latent_shapes:\n",
    "    log.info(\"Latent shape: {}\".format(latent_shape))\n",
    "\n",
    "key = watermark_filter.default_key(256)\n",
    "wf = watermark_filter.WatermarkFilter(key, watermark_shape, precision=16, probability=(5/1000))\n",
    "wf_latents = [\n",
    "    watermark_filter.WatermarkFilter(key, latent_shape, precision=16, probability=(50/1000))\n",
    "    for latent_shape in watermark_latent_shapes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:50.226251Z",
     "start_time": "2020-08-26T08:48:49.110603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1916088936ec47f3b63fbd828c53ede5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: Watermarked: 58\n",
      ">>> INFO: Not watermarked: 9942\n",
      ">>> INFO: Ratio: 0.5833836250251458\n",
      ">>> INFO: Watermarked latent: 529\n",
      ">>> INFO: Not watermarked latent: 9471\n",
      ">>> INFO: Ratio latent: 5.585471439129976\n",
      ">>> INFO: Watermarked latent: 521\n",
      ">>> INFO: Not watermarked latent: 9479\n",
      ">>> INFO: Ratio latent: 5.496360375567043\n"
     ]
    }
   ],
   "source": [
    "# Compare the distribution in the input space (image) to distribution of the latent representation\n",
    "lat = compare_distributions(model_victim, test_set, wf, wf_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:50.285484Z",
     "start_time": "2020-08-26T08:48:50.228523Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten(list_of_batches):\n",
    "    flat = []\n",
    "    for batch in list_of_batches:\n",
    "        for x in batch:\n",
    "            flat.append(x)\n",
    "    return flat\n",
    "            \n",
    "lat_flat = [flatten(list_of_batches) for list_of_batches in lat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:55.148907Z",
     "start_time": "2020-08-26T08:48:50.287494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee67e9a0fdc4b7bb51be15238973c9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acef7d01344488dbeca4e6f962b461b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_dist(latent_flat):\n",
    "    l = latent_flat[0].shape[0]\n",
    "    latent_dist = [[] for _ in range(l)]\n",
    "    \n",
    "    for single_lat in tqdm(latent_flat):\n",
    "        for i in range(l):\n",
    "            latent_dist[i].append(single_lat[i])\n",
    "        \n",
    "    return latent_dist\n",
    "\n",
    "lat_dists = [create_dist(single_flat_list) for single_flat_list in lat_flat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:59.550926Z",
     "start_time": "2020-08-26T08:48:55.150222Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate medians that are then used to partition the latent space.\n",
    "\n",
    "medians_for_lat = []\n",
    "for shape, lat_dist in zip(watermark_latent_shapes, lat_dists):\n",
    "    medians_for_single = []\n",
    "    \n",
    "    for dist in lat_dist:\n",
    "        d = np.asarray(dist)\n",
    "        median = np.median(d)\n",
    "        medians_for_single.append(median)\n",
    "#         Optional plotting\n",
    "#         plt.hist(d)\n",
    "#         plt.show()\n",
    "        \n",
    "    medians_for_lat.append(medians_for_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T08:48:59.571776Z",
     "start_time": "2020-08-26T08:48:59.552447Z"
    }
   },
   "outputs": [],
   "source": [
    "def median_featurize(tensor_vector, medians):\n",
    "    for idx, v in enumerate(medians):\n",
    "        tensor_vector[idx] = 0 if tensor_vector[idx] <= 0 else 1\n",
    "    \n",
    "    return tensor_vector\n",
    "\n",
    "def do_mapping(\n",
    "    model: nn.Module,\n",
    "    test_set: data.DataLoader,\n",
    "    wf_latent: watermark_filter.WatermarkFilter,\n",
    "    medians: List,\n",
    "    lat_idx,\n",
    "    eps_test):\n",
    "\n",
    "    matching = 0\n",
    "    not_matching = 0\n",
    "    matching_and_same_label = 0\n",
    "    matching_and_diff_label = 0\n",
    "    not_matching_and_same_label = 0\n",
    "    not_matching_and_diff_label = 0\n",
    "    to_wm_cnt = 0\n",
    "\n",
    "    new_img_per_orig = 10\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, _) in tqdm(test_set, unit=\"images\", desc=\"Watermark Filter\", leave=True, ascii=True):\n",
    "            inputs = inputs.cuda()\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            ypred, latents = model(inputs)\n",
    "            _, predicted = torch.max(ypred.data, 1)\n",
    "            lats = latents[idx]\n",
    "                \n",
    "            for x, l, yp in zip(inputs, lats, predicted):\n",
    "                perturbed = perturb(x, eps_test)\n",
    "\n",
    "                assert len(l.shape) == 1\n",
    "                to_wm = wf_latent.is_watermark(median_featurize(l.cpu(), medians))\n",
    "\n",
    "                if to_wm:\n",
    "                    to_wm_cnt += 1\n",
    "\n",
    "                for _ in range(new_img_per_orig):\n",
    "                    input_star = perturb(x, eps_test)\n",
    "\n",
    "                    ypred_star, lat_star = model(input_star.unsqueeze(0))\n",
    "                    _, predicted_star = torch.max(ypred_star.data, 1)\n",
    "                    predicted_star = predicted_star.squeeze()\n",
    "\n",
    "                    lat_star = lat_star[idx].squeeze(0)\n",
    "                    assert len(lat_star.shape) == 1\n",
    "                    to_wm_star = wf_latent.is_watermark(median_featurize(lat_star.cpu(), medians))\n",
    "\n",
    "                    if to_wm_star == to_wm:\n",
    "                        matching += 1\n",
    "                        if yp == predicted_star:\n",
    "                            matching_and_same_label += 1\n",
    "                        else:\n",
    "                            matching_and_diff_label += 1\n",
    "                    else:\n",
    "                        not_matching += 1\n",
    "                        if yp == predicted_star:\n",
    "                            not_matching_and_same_label += 1\n",
    "                        else:\n",
    "                            not_matching_and_diff_label += 1\n",
    "\n",
    "    log.info(\"to wm: {}\".format(to_wm_cnt))\n",
    "    log.info(\"matching: {} same label {} diff label {}\".format(\n",
    "        matching, matching_and_same_label, matching_and_diff_label))\n",
    "    log.info(\"not matching: {} same label {} diff label {}\".format(\n",
    "        not_matching, not_matching_and_same_label, not_matching_and_diff_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T09:25:42.922463Z",
     "start_time": "2020-08-26T08:48:59.572705Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "+++ with eps: 0.2\n",
      "\n",
      "latent size: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04455a1fb77041968a45f75f4411401a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 532\n",
      ">>> INFO: matching: 91836 same label 91604 diff label 232\n",
      ">>> INFO: not matching: 8164 same label 8151 diff label 13\n",
      "\n",
      "latent size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6ec352ac6d4c8aa71b4e79dddb60d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 1\n",
      ">>> INFO: matching: 99982 same label 99734 diff label 248\n",
      ">>> INFO: not matching: 18 same label 18 diff label 0\n",
      "---------------------------------------------------\n",
      "+++ with eps: 0.1\n",
      "\n",
      "latent size: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d8e8f9312b430a86e8f0a3f0f8276b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 532\n",
      ">>> INFO: matching: 93906 same label 93786 diff label 120\n",
      ">>> INFO: not matching: 6094 same label 6089 diff label 5\n",
      "\n",
      "latent size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6550d910ae564cf5a6b7eb254f7e6ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 1\n",
      ">>> INFO: matching: 99988 same label 99839 diff label 149\n",
      ">>> INFO: not matching: 12 same label 12 diff label 0\n",
      "---------------------------------------------------\n",
      "+++ with eps: 0.09\n",
      "\n",
      "latent size: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f2938ad4f443a1a8ef1dd4ad46fda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 532\n",
      ">>> INFO: matching: 94173 same label 94061 diff label 112\n",
      ">>> INFO: not matching: 5827 same label 5823 diff label 4\n",
      "\n",
      "latent size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31a92160b9b4d6897ad55643e740a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 1\n",
      ">>> INFO: matching: 99990 same label 99855 diff label 135\n",
      ">>> INFO: not matching: 10 same label 10 diff label 0\n",
      "---------------------------------------------------\n",
      "+++ with eps: 0.075\n",
      "\n",
      "latent size: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037bc259d1534e78825f84e3919433d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 532\n",
      ">>> INFO: matching: 94844 same label 94754 diff label 90\n",
      ">>> INFO: not matching: 5156 same label 5151 diff label 5\n",
      "\n",
      "latent size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761380a7411d4da993d64adc8ed364cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 1\n",
      ">>> INFO: matching: 99985 same label 99871 diff label 114\n",
      ">>> INFO: not matching: 15 same label 15 diff label 0\n",
      "---------------------------------------------------\n",
      "+++ with eps: 0.05\n",
      "\n",
      "latent size: 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9f8dbd0a4d4f94b4ccc53392d2498a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 532\n",
      ">>> INFO: matching: 96184 same label 96122 diff label 62\n",
      ">>> INFO: not matching: 3816 same label 3815 diff label 1\n",
      "\n",
      "latent size: 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c508e6cc752049e4a9186e4f95fbca37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Watermark Filter', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> INFO: to wm: 1\n",
      ">>> INFO: matching: 99988 same label 99920 diff label 68\n",
      ">>> INFO: not matching: 12 same label 12 diff label 0\n"
     ]
    }
   ],
   "source": [
    "for eps in [0.2, 0.1, 0.09, 0.075, 0.05]:\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(\"+++ with eps: {}\".format(eps))\n",
    "    for idx, wf in enumerate(wf_latents):\n",
    "        medians = medians_for_lat[idx]\n",
    "        print(\"\\nlatent size: {}\".format(len(medians)))\n",
    "        do_mapping(\n",
    "            model_victim,\n",
    "            test_set,\n",
    "            wf,\n",
    "            medians,\n",
    "            idx,\n",
    "            eps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
